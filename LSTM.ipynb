{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'UrbanSound8K.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\L_IACD\\SoundClassification\\ML2-Project\\LSTM\\LSTM.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/L_IACD/SoundClassification/ML2-Project/LSTM/LSTM.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mUrbanSound8K.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/L_IACD/SoundClassification/ML2-Project/LSTM/LSTM.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\anton\\anaconda3\\envs\\MachineLearning2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\anton\\anaconda3\\envs\\MachineLearning2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\anton\\anaconda3\\envs\\MachineLearning2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\anton\\anaconda3\\envs\\MachineLearning2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\anton\\anaconda3\\envs\\MachineLearning2\\lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'UrbanSound8K.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'UrbanSound8K.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Data distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels, counts = np.unique(df['classID'], return_counts=True)\n",
    "plt.bar(unique_labels, counts)\n",
    "plt.xlabel('Class Label')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Class distribution in dataset')\n",
    "plt.show()\n",
    "\n",
    "print(unique_labels, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick a sample to display  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6192, 4729\n",
    "sample_num = 4729\n",
    "\n",
    "# get the filename\n",
    "filename = df.slice_file_name[sample_num] \n",
    "print(filename)\n",
    "\n",
    "path = '../UrbanSound8K/audio/fold' + str(df.fold[sample_num]) + '/' + str(filename)\n",
    "signal, sr = librosa.load(path, sr=22050) # sr*T -> 22050*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveshow(signal, sr=sr)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFT -> Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft = np.fft.fft(signal)\n",
    "\n",
    "magnitude = np.abs(fft)\n",
    "frequency = np.linspace(0, sr, len(magnitude))\n",
    "left_frequency = frequency[:int(len(frequency)/2)]\n",
    "left_magnitude = magnitude[:int(len(frequency)/2)]\n",
    "\n",
    "plt.plot(left_frequency, left_magnitude)\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STFT -> Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 256\n",
    "hop_length = 512\n",
    "\n",
    "stft = librosa.core.stft(signal, hop_length=hop_length, n_fft=n_fft)\n",
    "spectogram = np.abs(stft)\n",
    "log_spectogram = librosa.amplitude_to_db(spectogram)\n",
    "\n",
    "librosa.display.specshow(log_spectogram, sr=sr, hop_length=hop_length)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print(len(log_spectogram))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFCCs = librosa.feature.mfcc(y=signal, n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "\n",
    "librosa.display.specshow(MFCCs, sr=sr, hop_length=hop_length)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"MFCC\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padded_data_nparray(audios_path, duration_secs = 4, sr = 22050, files_limit = -1, verbose = False):\n",
    "\n",
    "    files = librosa.util.find_files(audios_path)\n",
    "    data_array = []\n",
    "\n",
    "    for index, path_file in enumerate(files):\n",
    "        if files_limit != -1 and index >= files_limit: break\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"At audio {index+1}/{len(files)}\")\n",
    "            \n",
    "        signal, sr = librosa.load(path_file, sr = sr, mono=True)\n",
    "        \n",
    "        # zero padding\n",
    "        if len(signal) < duration_secs*sr:\n",
    "            signal = np.concatenate([\n",
    "                signal,\n",
    "                np.zeros(shape = (duration_secs*sr - len(signal), ))\n",
    "            ])\n",
    "        elif len(signal) > duration_secs*sr:\n",
    "            signal = signal[:duration_secs*sr]\n",
    "            \n",
    "\n",
    "        if len(signal) == duration_secs*sr:\n",
    "            lst = path_file.split(\"\\\\\")\n",
    "            file_name = lst[-1]\n",
    "            newrow = [file_name, signal]\n",
    "            data_array.append(newrow)\n",
    "        else:\n",
    "            print(file_name)\n",
    "            print(path_file) \n",
    "        \n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature extraction -> MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df_in, signals, hop_length = 512, n_fft = 2048, n_mfcc = 40, sr = 44100):\n",
    "    \n",
    "    MFCCS = [] # list to save MFCCs\n",
    "    SPECTOGRAM = [] # list to save Spectograms\n",
    "    labels = [] # list to save labels\n",
    "    \n",
    "    for index in range(len(signals)):\n",
    "\n",
    "        # get the filename        \n",
    "        filename = signals[index][0]\n",
    "        if filename:\n",
    "            \n",
    "            # find correspondig row in df_in\n",
    "            row = df_in.loc[df_in[\"slice_file_name\"] == filename]\n",
    "\n",
    "            if not row.empty:\n",
    "                # save labels\n",
    "                label = row.iloc[0,6] \n",
    "                \n",
    "                # Extracting MFCCs\n",
    "                mfcc = librosa.feature.mfcc(y = np.array(signals[index][1]), \n",
    "                                            sr=sr, \n",
    "                                            n_fft = n_fft,  \n",
    "                                            n_mfcc = n_mfcc,\n",
    "                                            hop_length = hop_length)\n",
    "                mfcc = mfcc.T\n",
    " \n",
    "                MFCCS.append(np.array([mfcc]))\n",
    "\n",
    "\n",
    "                # Extracting Spectograms\n",
    "                stft = librosa.core.stft(y = np.array(signals[index][1]), \n",
    "                                         hop_length=hop_length, \n",
    "                                         n_fft=246)\n",
    "                spectogram = np.abs(stft)\n",
    "                log_spectogram = librosa.amplitude_to_db(spectogram)\n",
    "\n",
    "                SPECTOGRAM.append(np.array([log_spectogram]))\n",
    "                \n",
    "                # Extracting labels\n",
    "                labels.append(label)\n",
    "                \n",
    "            else: \n",
    "                print(f\"No matching row for filename {filename}\")\n",
    "        else:\n",
    "            print(\"Empty filename\")\n",
    "\n",
    "    # check is features and labels  have the same lenght\n",
    "    assert len(MFCCS) == len(labels) == len(SPECTOGRAM)\n",
    "\n",
    "\n",
    "    mfcc = np.concatenate(MFCCS, axis = 0)\n",
    "    spec = np.concatenate(SPECTOGRAM, axis = 0)\n",
    "    return(np.array(mfcc), np.array(spec), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Data to Pickel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pkl(data, path):\n",
    "    with open(path, \"wb\") as saved_data:\n",
    "        pickle.dump(data, saved_data)\n",
    "    saved_data.close()\n",
    "\n",
    "def load_pkl(path):\n",
    "    to_return = None\n",
    "    with open(path, \"rb\") as loaded_data:\n",
    "        to_return = pickle.load(loaded_data)\n",
    "    loaded_data.close()\n",
    "    return to_return\n",
    "\n",
    "def numpy_array_float_32(data):\n",
    "    return np.asarray(tuple(data)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_paths = [\"../UrbanSound8K/audio/fold1/\", \"../UrbanSound8K/audio/fold2/\", \"../UrbanSound8K/audio/fold3/\",\n",
    "              \"../UrbanSound8K/audio/fold4/\", \"../UrbanSound8K/audio/fold5/\", \"../UrbanSound8K/audio/fold6/\",\n",
    "              \"../UrbanSound8K/audio/fold7/\", \"../UrbanSound8K/audio/fold8/\", \"../UrbanSound8K/audio/fold9/\",\n",
    "              \"../UrbanSound8K/audio/fold10/\"]\n",
    "\n",
    "mfcc = [10]\n",
    "spec = [10]\n",
    "labels = [10]\n",
    "\n",
    "for i in range(len(fold_paths)): \n",
    "    print(fold_paths[i])\n",
    "\n",
    "    # Adding ZEro-Padding to audio \n",
    "    audio = zero_padded_data_nparray(fold_paths[i])\n",
    "\n",
    "    # Feature Extraction\n",
    "    mfccs, spectograms, y = get_features(df, audio)\n",
    "\n",
    "    # Data Normalization Min-Max scaling to [0, 1] \n",
    "    mfccs_scaled = (mfccs - np.min(mfccs)) / (np.max(mfccs) - np.min(mfccs))\n",
    "    spectograms_scaled = (spectograms - np.min(spectograms)) / (np.max(spectograms) - np.min(spectograms))\n",
    "\n",
    "    # One-Hot Encoding Target feature\n",
    "    y_encoded = np.zeros((len(y), max(y) +1))\n",
    "    y_encoded[np.arange(len(y)), y] = 1\n",
    "\n",
    "    # Saving Features and Labels to \n",
    "    mfcc.append(np.array(mfccs_scaled))\n",
    "    spec.append(np.array(spectograms_scaled))\n",
    "    labels.append(y_encoded)\n",
    "\n",
    "mfcc = mfcc[1:]\n",
    "spec = spec[1:]\n",
    "labels = labels[1:]\n",
    "\n",
    "save_pkl(mfcc, \"./mfcc.pkl\")\n",
    "save_pkl(spec, \"./spec.pkl\")\n",
    "save_pkl(labels, \"./labels.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Recurent Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Network topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_shape = (124,173) # shape of X_train\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # 2 LSTM layers\n",
    "    model.add(layers.LSTM(128,  input_shape = input_shape, return_sequences = True, activation='tanh', kernel_initializer='random_normal'))\n",
    "    model.add(layers.LSTM(128, return_sequences = True, activation='tanh'))\n",
    "\n",
    "    #model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.TimeDistributed(layers.Dense(128, activation = 'tanh', kernel_regularizer = regularizers.l2(0.01))))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.TimeDistributed(layers.Dense(64, activation='tanh', kernel_regularizer = regularizers.l2(0.01))))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.TimeDistributed(layers.Dense(32, activation='tanh', kernel_regularizer = regularizers.l2(0.01))))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.TimeDistributed(layers.Dense(16, activation='tanh', kernel_regularizer = regularizers.l2(0.01))))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.TimeDistributed(layers.Dense(8, activation='tanh', kernel_regularizer = regularizers.l2(0.01))))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "\n",
    "    #model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Flatten layer \n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Output layer\n",
    "    model.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the graph of the LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the Model\n",
    "\n",
    "The **Adam** optimizer manages the learning rate for stochastic gradient descent. The loss function is **categorical_crossentropy**, which is used when the target label is One-Hot-Encoded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = keras.optimizers.Adam(learning_rate = 0.001)\n",
    "optimizer2 = keras.optimizers.SGD(clipvalue = 0.8, learning_rate = 0.0001)\n",
    "\n",
    "model.compile(optimizer = optimizer1, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, to analyse the 10 models made in the 10 fold cross validation, we will keep useful info in some arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_metrics = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be fit using the Adam optimizar, we will use categorical (hence why we one hot encoded the class labels) crossentropy as our loss function, and we will use accuracy to analyse how well our model performs.\n",
    "\n",
    "We will also input the data in batches of 64, and, from previous testings, we will define the number of epochs to 60, as more start to take too much time to train with a low yield of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape: (6193, 124, 173)\n",
      "X_test Shape: (990, 124, 173)\n",
      "Epoch 1/50\n",
      "78/78 [==============================] - 54s 422ms/step - loss: 4.5547 - accuracy: 0.1683 - val_loss: 3.7464 - val_accuracy: 0.2930\n",
      "Epoch 2/50\n",
      "78/78 [==============================] - 31s 394ms/step - loss: 3.3415 - accuracy: 0.2418 - val_loss: 3.0116 - val_accuracy: 0.2809\n",
      "Epoch 3/50\n",
      "78/78 [==============================] - 30s 379ms/step - loss: 2.7079 - accuracy: 0.2931 - val_loss: 2.5133 - val_accuracy: 0.3293\n",
      "Epoch 4/50\n",
      "78/78 [==============================] - 30s 383ms/step - loss: 2.3116 - accuracy: 0.3246 - val_loss: 2.2421 - val_accuracy: 0.3099\n",
      "Epoch 5/50\n",
      "78/78 [==============================] - 30s 385ms/step - loss: 2.0856 - accuracy: 0.3466 - val_loss: 1.9794 - val_accuracy: 0.3826\n",
      "Epoch 6/50\n",
      "78/78 [==============================] - 30s 384ms/step - loss: 1.9064 - accuracy: 0.3807 - val_loss: 1.8776 - val_accuracy: 0.3939\n",
      "Epoch 7/50\n",
      "78/78 [==============================] - 30s 385ms/step - loss: 1.8181 - accuracy: 0.3916 - val_loss: 1.7455 - val_accuracy: 0.4205\n",
      "Epoch 8/50\n",
      "78/78 [==============================] - 31s 403ms/step - loss: 1.7089 - accuracy: 0.4396 - val_loss: 1.6974 - val_accuracy: 0.4479\n",
      "Epoch 9/50\n",
      "78/78 [==============================] - 31s 402ms/step - loss: 1.6195 - accuracy: 0.4651 - val_loss: 1.6019 - val_accuracy: 0.4471\n",
      "Epoch 10/50\n",
      "78/78 [==============================] - 32s 404ms/step - loss: 1.5592 - accuracy: 0.4839 - val_loss: 1.4663 - val_accuracy: 0.5222\n",
      "Epoch 11/50\n",
      "78/78 [==============================] - 32s 409ms/step - loss: 1.4919 - accuracy: 0.5139 - val_loss: 1.4689 - val_accuracy: 0.5182\n",
      "Epoch 12/50\n",
      "78/78 [==============================] - 33s 424ms/step - loss: 1.4463 - accuracy: 0.5204 - val_loss: 1.4328 - val_accuracy: 0.5254\n",
      "Epoch 13/50\n",
      "78/78 [==============================] - 33s 418ms/step - loss: 1.4181 - accuracy: 0.5307 - val_loss: 1.3778 - val_accuracy: 0.5400\n",
      "Epoch 14/50\n",
      "78/78 [==============================] - 32s 413ms/step - loss: 1.4026 - accuracy: 0.5349 - val_loss: 1.4111 - val_accuracy: 0.5375\n",
      "Epoch 15/50\n",
      "78/78 [==============================] - 33s 419ms/step - loss: 1.3551 - accuracy: 0.5551 - val_loss: 1.3069 - val_accuracy: 0.5747\n",
      "Epoch 16/50\n",
      "78/78 [==============================] - 34s 432ms/step - loss: 1.3249 - accuracy: 0.5628 - val_loss: 1.2774 - val_accuracy: 0.5682\n",
      "Epoch 17/50\n",
      "78/78 [==============================] - 33s 426ms/step - loss: 1.2854 - accuracy: 0.5779 - val_loss: 1.2875 - val_accuracy: 0.5706\n",
      "Epoch 18/50\n",
      "78/78 [==============================] - 40s 515ms/step - loss: 1.2596 - accuracy: 0.5805 - val_loss: 1.2343 - val_accuracy: 0.5916\n",
      "Epoch 19/50\n",
      "78/78 [==============================] - 35s 451ms/step - loss: 1.2318 - accuracy: 0.6005 - val_loss: 1.2132 - val_accuracy: 0.5908\n",
      "Epoch 20/50\n",
      "78/78 [==============================] - 35s 455ms/step - loss: 1.2106 - accuracy: 0.6110 - val_loss: 1.1773 - val_accuracy: 0.6182\n",
      "Epoch 21/50\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 1.1578 - accuracy: 0.6328 - val_loss: 1.1881 - val_accuracy: 0.6255\n",
      "Epoch 22/50\n",
      "78/78 [==============================] - 35s 450ms/step - loss: 1.1737 - accuracy: 0.6231 - val_loss: 1.1085 - val_accuracy: 0.6473\n",
      "Epoch 23/50\n",
      "78/78 [==============================] - 34s 430ms/step - loss: 1.1144 - accuracy: 0.6490 - val_loss: 1.1421 - val_accuracy: 0.6376\n",
      "Epoch 24/50\n",
      "78/78 [==============================] - 38s 494ms/step - loss: 1.1012 - accuracy: 0.6463 - val_loss: 1.1332 - val_accuracy: 0.6505\n",
      "Epoch 25/50\n",
      "78/78 [==============================] - 35s 450ms/step - loss: 1.0755 - accuracy: 0.6542 - val_loss: 1.1124 - val_accuracy: 0.6691\n",
      "Epoch 26/50\n",
      "78/78 [==============================] - 33s 428ms/step - loss: 1.0324 - accuracy: 0.6702 - val_loss: 1.1195 - val_accuracy: 0.6634\n",
      "Epoch 27/50\n",
      "78/78 [==============================] - 34s 432ms/step - loss: 1.1802 - accuracy: 0.6237 - val_loss: 1.1368 - val_accuracy: 0.6328\n",
      "Epoch 28/50\n",
      "78/78 [==============================] - 34s 434ms/step - loss: 1.0120 - accuracy: 0.6845 - val_loss: 1.0807 - val_accuracy: 0.6546\n",
      "Epoch 29/50\n",
      "78/78 [==============================] - 34s 434ms/step - loss: 0.9785 - accuracy: 0.6934 - val_loss: 1.0737 - val_accuracy: 0.6651\n",
      "Epoch 30/50\n",
      "78/78 [==============================] - 35s 451ms/step - loss: 0.9469 - accuracy: 0.7083 - val_loss: 1.0187 - val_accuracy: 0.6885\n",
      "Epoch 31/50\n",
      "78/78 [==============================] - 36s 462ms/step - loss: 0.9470 - accuracy: 0.6970 - val_loss: 1.0240 - val_accuracy: 0.6860\n",
      "Epoch 32/50\n",
      "78/78 [==============================] - 36s 457ms/step - loss: 0.9008 - accuracy: 0.7117 - val_loss: 0.9949 - val_accuracy: 0.6949\n",
      "Epoch 33/50\n",
      "78/78 [==============================] - 35s 444ms/step - loss: 0.8962 - accuracy: 0.7200 - val_loss: 0.9698 - val_accuracy: 0.7014\n",
      "Epoch 34/50\n",
      "78/78 [==============================] - 34s 434ms/step - loss: 0.8745 - accuracy: 0.7285 - val_loss: 0.9620 - val_accuracy: 0.7135\n",
      "Epoch 35/50\n",
      "78/78 [==============================] - 34s 440ms/step - loss: 0.8700 - accuracy: 0.7253 - val_loss: 0.9955 - val_accuracy: 0.6933\n",
      "Epoch 36/50\n",
      "78/78 [==============================] - 34s 437ms/step - loss: 0.8501 - accuracy: 0.7307 - val_loss: 0.9265 - val_accuracy: 0.7143\n",
      "Epoch 37/50\n",
      "78/78 [==============================] - 34s 434ms/step - loss: 0.8394 - accuracy: 0.7459 - val_loss: 0.9858 - val_accuracy: 0.7054\n",
      "Epoch 38/50\n",
      "78/78 [==============================] - 35s 445ms/step - loss: 0.9342 - accuracy: 0.7069 - val_loss: 0.9365 - val_accuracy: 0.7151\n",
      "Epoch 39/50\n",
      "78/78 [==============================] - 35s 450ms/step - loss: 0.7849 - accuracy: 0.7600 - val_loss: 1.0259 - val_accuracy: 0.6957\n",
      "Epoch 40/50\n",
      "78/78 [==============================] - 34s 443ms/step - loss: 0.7650 - accuracy: 0.7616 - val_loss: 0.9020 - val_accuracy: 0.7425\n",
      "Epoch 41/50\n",
      "78/78 [==============================] - 35s 445ms/step - loss: 0.7354 - accuracy: 0.7757 - val_loss: 0.9061 - val_accuracy: 0.7401\n",
      "Epoch 42/50\n",
      "78/78 [==============================] - 35s 444ms/step - loss: 0.7339 - accuracy: 0.7776 - val_loss: 0.9526 - val_accuracy: 0.7207\n",
      "Epoch 43/50\n",
      "78/78 [==============================] - 37s 475ms/step - loss: 0.7290 - accuracy: 0.7776 - val_loss: 0.9344 - val_accuracy: 0.7312\n",
      "Epoch 44/50\n",
      "78/78 [==============================] - 34s 436ms/step - loss: 0.6858 - accuracy: 0.7959 - val_loss: 0.8862 - val_accuracy: 0.7441\n",
      "Epoch 45/50\n",
      "78/78 [==============================] - 35s 450ms/step - loss: 0.6666 - accuracy: 0.7990 - val_loss: 0.9221 - val_accuracy: 0.7514\n",
      "Epoch 46/50\n",
      "78/78 [==============================] - 35s 449ms/step - loss: 0.6706 - accuracy: 0.7981 - val_loss: 0.8708 - val_accuracy: 0.7506\n",
      "Epoch 47/50\n",
      "78/78 [==============================] - 34s 430ms/step - loss: 0.6344 - accuracy: 0.8088 - val_loss: 0.8664 - val_accuracy: 0.7643\n",
      "Epoch 48/50\n",
      "78/78 [==============================] - 34s 436ms/step - loss: 0.6480 - accuracy: 0.8070 - val_loss: 0.9648 - val_accuracy: 0.7272\n",
      "Epoch 49/50\n",
      "78/78 [==============================] - 34s 440ms/step - loss: 0.6557 - accuracy: 0.8060 - val_loss: 0.9760 - val_accuracy: 0.7328\n",
      "Epoch 50/50\n",
      "78/78 [==============================] - 37s 480ms/step - loss: 0.6002 - accuracy: 0.8232 - val_loss: 0.9539 - val_accuracy: 0.7256\n",
      "31/31 [==============================] - 22s 82ms/step\n",
      "31/31 [==============================] - 3s 81ms/step - loss: 2.1735 - accuracy: 0.5030\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 60\n",
    "features = spec\n",
    "\n",
    "for fold in range(10):\n",
    "    fold = \"fold\" + str(i+1)\n",
    "    print(\"Fold \"+str(i)+\":\")\n",
    "\n",
    "    X_train, y_train = [], []\n",
    "    X_test, y_test = [], []\n",
    "        \n",
    "    # Splitting the data into Test, Validation and Training sets\n",
    "    for i in range(10):\n",
    "        if( i != fold):\n",
    "            X_train += features[i].tolist()\n",
    "            y_train.extend(labels[i])\n",
    "            \n",
    "        else:\n",
    "            X_test = features[i]\n",
    "            y_test = labels[i]\n",
    "\n",
    "        \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "            \n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5, random_state = 123)\n",
    "\n",
    "    # Print sets shapes\n",
    "    print(f\"X_train Shape: {X_train.shape}\")\n",
    "    print(f\"X_test Shape: {X_test.shape}\")\n",
    "    print(f\"X_val Shape: {X_val.shape}\")\n",
    "\n",
    "    # Create & Compile model\n",
    "    model = create_model()\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.001)\n",
    "    model.compile(\n",
    "        optimizer = optimizer, \n",
    "        loss = 'categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    LSTM = model.fit(\n",
    "        X_train, y_train, \n",
    "        epochs = EPOCHS, \n",
    "        batch_size = 64, \n",
    "        shuffle=False, \n",
    "        validation_data=(X_val, y_val)\n",
    "    )\n",
    "\n",
    "    # Predict unseen data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    y_pred_reshape = np.argmax(y_pred, axis=1)\n",
    "    y_test_reshape = np.argmax(y_test, axis=1)\n",
    "    TestLoss, Testacc = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    # Save fold results\n",
    "    m_metrics = {\n",
    "        'loss': TestLoss, \n",
    "        'accuracy': Testacc, \n",
    "        'confusion_matrix': confusion_matrix(y_test_reshape, y_pred_reshape), \n",
    "        'history': model, 'history_dict': LSTM.history\n",
    "    }\n",
    "    fold_metrics.append(m_metrics)\n",
    "\n",
    "    save_pkl(m_metrics, f\"assets/kfold_metrics/metrics_fold{i+1}.pkl\")\n",
    "\n",
    "    model.save(f\"assets/kfold_metrics/model_fold{i+1}.keras\", save_format=\"keras\")\n",
    "    save_pkl(fold_metrics, \"assets/kfold_metrics/metrics.pkl\")\n",
    "\n",
    "    # restart model to avoid memory leakage\n",
    "    del model \n",
    "\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model Analysis\n",
    "\n",
    "#### Accuracy & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = range(1, EPOCHS + 1)\n",
    "\n",
    "fig, ax = plt.subplots(len(fold_metrics),2,figsize=(10,5*len(fold_metrics)))\n",
    "\n",
    "for i in range(0,len(fold_metrics)):\n",
    "    history_dict = fold_metrics[i].get('history_dict')\n",
    "    loss_values=history_dict['loss']\n",
    "    acc_values=history_dict['accuracy']\n",
    "    val_loss_values = history_dict['val_loss']\n",
    "    val_acc_values = history_dict['val_accuracy']\n",
    "\n",
    "    ax[i,0].plot(epochs,loss_values,'co',label='Training Loss')\n",
    "    ax[i,0].plot(epochs,val_loss_values,'m', label='Validation Loss')\n",
    "    ax[i,0].set_title('Training and validation loss on fold '+str(i+1)+' of 10')\n",
    "    ax[i,0].set_xlabel('Epochs')\n",
    "    ax[i,0].set_ylabel('Loss')\n",
    "    ax[i,0].legend()\n",
    "\n",
    "    ax[i,1].plot(epochs,acc_values,'co', label='Training accuracy')\n",
    "    ax[i,1].plot(epochs,val_acc_values,'m', label='Validation accuracy')\n",
    "    ax[i,1].set_title('Training and validation accuracy on fold '+str(i+1)+' of 10')\n",
    "    ax[i,1].set_xlabel('Epochs')\n",
    "    ax[i,1].set_ylabel('Accuracy')\n",
    "    ax[i,1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_train_acc = 0\n",
    "for i in fold_metrics:\n",
    "    avg_train_acc += max(i.get('history_dict').get('accuracy'))\n",
    "    \n",
    "print(str(avg_train_acc / len(fold_metrics)) + \" average train accuracy across all folds.\")\n",
    "\n",
    "avg_val_acc = 0\n",
    "for i in fold_metrics:\n",
    "    avg_val_acc += max(i.get('history_dict').get('val_accuracy'))\n",
    "\n",
    "print(str(avg_val_acc / len(fold_metrics)) + \" average validation accuracy across all folds.\")\n",
    "\n",
    "avg_test_acc = 0\n",
    "for i in fold_metrics:\n",
    "    avg_test_acc += i.get('accuracy')\n",
    "\n",
    "print(str(avg_test_acc / len(fold_metrics)) + \" average test accuracy across all folds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax =plt.subplots(5, 2, figsize=(15,5*len(fold_metrics)))\n",
    "\n",
    "for i in range(0,len(fold_metrics)):\n",
    "    cm = fold_metrics[i].get('confusion_matrix')\n",
    "    ax[i//2,i%2].set_title('Confusion matrix on fold '+str(i+1)+' of 10')\n",
    "    ax[i//2,i%2].set_xlabel('Predicted label')\n",
    "    ax[i//2,i%2].set_ylabel('Actual label')\n",
    "    ax[i//2,i%2].invert_yaxis()\n",
    "    sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'RdYlGn', ax=ax[i//2,i%2])\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
