{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello this is a CNN\n",
    "I am doing it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure\n",
    "\n",
    "We will have 4 separated convolutional networks, three for the 2D features and another to the 1D data, that will be flattened and concatenated into a MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Features & Shapes:\n",
    "\n",
    "- 2D Chromagram: (12, 321)\n",
    "- 2D Mel Spectogram: (128, 321)\n",
    "- 2D Fourier Tempogram: (508, 322)\n",
    "- 1D Features: (40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chromagram Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromagram_shape = (12, 321, 1)\n",
    "\n",
    "chromagram_input = keras.Input(shape=chromagram_shape, name='chromagram_input')\n",
    "\n",
    "chromalayer = layers.Conv2D(64, (3,3), activation='relu')(chromagram_input)\n",
    "chromalayer = layers.MaxPooling2D((2,2))(chromalayer)\n",
    "chromalayer = layers.Dropout(0.2)(chromalayer)\n",
    "chromalayer = layers.Conv2D(128, (3,3), activation='relu')(chromalayer)\n",
    "chromalayer = layers.MaxPooling2D((2,2))(chromalayer)\n",
    "chromalayer = layers.Dropout(0.2)(chromalayer)\n",
    "chromalayer = layers.Flatten()(chromalayer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mel Spectrogram Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_shape = (128, 321, 1)\n",
    "\n",
    "mel_spectogram_input = keras.Input(shape=mel_shape, name='mel_spectogram_input')\n",
    "\n",
    "mellayer = layers.Conv2D(32, (3,3), activation='relu')(mel_spectogram_input)\n",
    "mellayer = layers.MaxPooling2D((2,2))(mellayer)\n",
    "mellayer = layers.Dropout(0.2)(mellayer)\n",
    "mellayer = layers.Conv2D(64, (3,3), activation='relu')(mellayer)\n",
    "mellayer = layers.MaxPooling2D((2,2))(mellayer)\n",
    "mellayer = layers.Dropout(0.2)(mellayer)\n",
    "mellayer = layers.Flatten()(mellayer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourier Tempogram Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempogram_shape = (508, 322, 1)\n",
    "\n",
    "fourier_tempogram = keras.Input(shape=tempogram_shape, name='fourier_tempogram')\n",
    "\n",
    "fourierlayer = layers.Conv2D(32, (3,3), activation='relu')(fourier_tempogram)\n",
    "fourierlayer = layers.MaxPooling2D((2,2))(fourierlayer)\n",
    "fourierlayer = layers.Dropout(0.2)(fourierlayer)\n",
    "fourierlayer = layers.Conv2D(64, (3,3), activation='relu')(fourierlayer)\n",
    "fourierlayer = layers.MaxPooling2D((2,2))(fourierlayer)\n",
    "fourierlayer = layers.Dropout(0.2)(fourierlayer)\n",
    "fourierlayer = layers.Conv2D(64, (3,3), activation='relu')(fourierlayer)\n",
    "fourierlayer = layers.Flatten()(fourierlayer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Features Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1d_shape = (321, 4)\n",
    "\n",
    "features_1d = keras.Input(shape=features_1d_shape, name='features_1d')\n",
    "\n",
    "featureslayer = layers.Conv1D(32, 3, activation='relu')(features_1d)\n",
    "featureslayer = layers.MaxPooling1D(2)(featureslayer)\n",
    "featureslayer = layers.Dropout(0.2)(featureslayer)\n",
    "featureslayer = layers.Conv1D(64, 3, activation='relu')(featureslayer)\n",
    "featureslayer = layers.MaxPooling1D(2)(featureslayer)\n",
    "featureslayer = layers.Dropout(0.2)(featureslayer)\n",
    "featureslayer = layers.Conv1D(64, 3, activation='relu')(featureslayer)\n",
    "featureslayer = layers.Flatten()(featureslayer)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "fourier_tempogram (InputLayer)  [(None, 508, 322, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "features_1d (InputLayer)        [(None, 321, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chromagram_input (InputLayer)   [(None, 12, 321, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 506, 320, 32) 320         fourier_tempogram[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mel_spectogram_input (InputLaye [(None, 128, 321, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 319, 32)      416         features_1d[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 10, 319, 64)  640         chromagram_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 253, 160, 32) 0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 126, 319, 32) 320         mel_spectogram_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 159, 32)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 5, 159, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 253, 160, 32) 0           max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 63, 159, 32)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 159, 32)      0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 5, 159, 64)   0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 251, 158, 64) 18496       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 63, 159, 32)  0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 157, 64)      6208        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 3, 157, 128)  73856       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 125, 79, 64)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 61, 157, 64)  18496       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 78, 64)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 1, 78, 128)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 125, 79, 64)  0           max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 30, 78, 64)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 78, 64)       0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1, 78, 128)   0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 123, 77, 64)  36928       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 30, 78, 64)   0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 76, 64)       12352       dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 9984)         0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 606144)       0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 149760)       0           dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 4864)         0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 770752)       0           flatten_4[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          98656384    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 128)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           8256        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 64)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           2080        dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 32)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           330         dropout_21[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 98,835,082\n",
      "Trainable params: 98,835,082\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined = layers.concatenate([chromalayer, fourierlayer, mellayer, featureslayer])\n",
    "combined = layers.Dense(128, activation='relu')(combined)\n",
    "combined = layers.Dropout(0.3)(combined)\n",
    "combined = layers.Dense(64, activation='relu')(combined)\n",
    "combined = layers.Dropout(0.3)(combined)\n",
    "combined = layers.Dense(32, activation='softmax')(combined)\n",
    "combined = layers.Dropout(0.3)(combined)\n",
    "combined = layers.Dense(10, activation='softmax')(combined)\n",
    "\n",
    "model = keras.Model(inputs=[chromagram_input, mel_spectogram_input, fourier_tempogram, features_1d], outputs=combined)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('../cnn_folds_dataframes/fold5_df.pkl', 'rb') as f:\n",
    "    conv_data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "conv_data = pd.DataFrame(conv_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = conv_data.drop(columns=['slice_file_name','classID'])\n",
    "y = conv_data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=conv_data['classID'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating the test train into the respective layer inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_chroma = np.asarray(tuple(X_train[\"chromagram\"].to_list())).astype(np.float32)\n",
    "X_train_mel = np.asarray(tuple(X_train[\"mel_spectogram\"].to_list())).astype(np.float32)\n",
    "X_train_fourier = np.asarray(tuple(X_train[\"fourier_tempogram\"].to_list())).astype(np.float32)\n",
    "X_train_1d = X_train.drop(columns=['chromagram','mel_spectogram','fourier_tempogram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1d = np.stack([\n",
    "    np.asarray(tuple(X_train_1d[\"spectral_centroid\"].to_list())).astype(np.float32),\n",
    "    np.asarray(tuple(X_train_1d[\"spectral_bandwidth\"].to_list())).astype(np.float32),\n",
    "    np.asarray(tuple(X_train_1d[\"spectral_flatness\"].to_list())).astype(np.float32),\n",
    "    np.asarray(tuple(X_train_1d[\"spectral_rolloff\"].to_list())).astype(np.float32)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\ML2 Project\\ML2-Project\\allegedCnn.ipynb Cell 24\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ML2%20Project/ML2-Project/allegedCnn.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ML2%20Project/ML2-Project/allegedCnn.ipynb#Y116sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ML2%20Project/ML2-Project/allegedCnn.ipynb#Y116sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ML2%20Project/ML2-Project/allegedCnn.ipynb#Y116sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ML2%20Project/ML2-Project/allegedCnn.ipynb#Y116sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     )\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ML2%20Project/ML2-Project/allegedCnn.ipynb#Y116sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ML2%20Project/ML2-Project/allegedCnn.ipynb#Y116sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     x\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mfeatures_1d\u001b[39;49m\u001b[39m'\u001b[39;49m: X_train_1d, \u001b[39m'\u001b[39;49m\u001b[39mchromagram_input\u001b[39;49m\u001b[39m'\u001b[39;49m: X_train_chroma, \u001b[39m'\u001b[39;49m\u001b[39mmel_spectogram_input\u001b[39;49m\u001b[39m'\u001b[39;49m: X_train_mel, \u001b[39m'\u001b[39;49m\u001b[39mfourier_tempogram\u001b[39;49m\u001b[39m'\u001b[39;49m: X_train_fourier},\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ML2%20Project/ML2-Project/allegedCnn.ipynb#Y116sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     y\u001b[39m=\u001b[39;49my_train\u001b[39m.\u001b[39;49mto_numpy(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ML2%20Project/ML2-Project/allegedCnn.ipynb#Y116sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ML2%20Project/ML2-Project/allegedCnn.ipynb#Y116sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ML2%20Project/ML2-Project/allegedCnn.ipynb#Y116sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_method_wrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    107\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_multi_worker_mode():  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    110\u001b[0m   \u001b[39m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m   \u001b[39mif\u001b[39;00m dc_context\u001b[39m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1049\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1043\u001b[0m   val_x, val_y, val_sample_weight \u001b[39m=\u001b[39m (\n\u001b[0;32m   1044\u001b[0m       data_adapter\u001b[39m.\u001b[39munpack_x_y_sample_weight(validation_data))\n\u001b[0;32m   1046\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mscope(), \\\n\u001b[0;32m   1047\u001b[0m      training_utils\u001b[39m.\u001b[39mRespectCompiledTrainableState(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1048\u001b[0m   \u001b[39m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[1;32m-> 1049\u001b[0m   data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mDataHandler(\n\u001b[0;32m   1050\u001b[0m       x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m   1051\u001b[0m       y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m   1052\u001b[0m       sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1053\u001b[0m       batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1054\u001b[0m       steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1055\u001b[0m       initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m   1056\u001b[0m       epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   1057\u001b[0m       shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1058\u001b[0m       class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   1059\u001b[0m       max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1060\u001b[0m       workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1061\u001b[0m       use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1062\u001b[0m       model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1063\u001b[0m       steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution)\n\u001b[0;32m   1065\u001b[0m   \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1105\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1102\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution_value \u001b[39m=\u001b[39m steps_per_execution\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m   1104\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[0;32m   1106\u001b[0m     x,\n\u001b[0;32m   1107\u001b[0m     y,\n\u001b[0;32m   1108\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1109\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1110\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[0;32m   1111\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1112\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1113\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1114\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1115\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1116\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mds_context\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[0;32m   1117\u001b[0m     model\u001b[39m=\u001b[39;49mmodel)\n\u001b[0;32m   1119\u001b[0m strategy \u001b[39m=\u001b[39m ds_context\u001b[39m.\u001b[39mget_strategy()\n\u001b[0;32m   1120\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter\u001b[39m.\u001b[39mget_dataset()\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:265\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m    255\u001b[0m              x,\n\u001b[0;32m    256\u001b[0m              y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m              shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    263\u001b[0m              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    264\u001b[0m   \u001b[39msuper\u001b[39m(TensorLikeDataAdapter, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(x, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 265\u001b[0m   x, y, sample_weights \u001b[39m=\u001b[39m _process_tensorlike((x, y, sample_weights))\n\u001b[0;32m    266\u001b[0m   sample_weight_modes \u001b[39m=\u001b[39m broadcast_sample_weight_modes(\n\u001b[0;32m    267\u001b[0m       sample_weights, sample_weight_modes)\n\u001b[0;32m    269\u001b[0m   \u001b[39m# If sample_weights are not specified for an output use 1.0 as weights.\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1021\u001b[0m, in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     \u001b[39mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n\u001b[0;32m   1019\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m-> 1021\u001b[0m inputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39;49mmap_structure(_convert_numpy_and_scipy, inputs)\n\u001b[0;32m   1022\u001b[0m \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39mlist_to_tuple(inputs)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:635\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m flat_structure \u001b[39m=\u001b[39m [flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure]\n\u001b[0;32m    632\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    634\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 635\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    636\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:635\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    631\u001b[0m flat_structure \u001b[39m=\u001b[39m [flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure]\n\u001b[0;32m    632\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    634\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 635\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    636\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1016\u001b[0m, in \u001b[0;36m_process_tensorlike.<locals>._convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1014\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(x\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, np\u001b[39m.\u001b[39mfloating):\n\u001b[0;32m   1015\u001b[0m     dtype \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mfloatx()\n\u001b[1;32m-> 1016\u001b[0m   \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(x, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m   1017\u001b[0m \u001b[39melif\u001b[39;00m scipy_sparse \u001b[39mand\u001b[39;00m scipy_sparse\u001b[39m.\u001b[39missparse(x):\n\u001b[0;32m   1018\u001b[0m   \u001b[39mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1499\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1494\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor did not convert to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1495\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mthe preferred dtype: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1496\u001b[0m                       (ret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype, preferred_dtype\u001b[39m.\u001b[39mbase_dtype))\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1499\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m   1501\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   1502\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:52\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[0;32m     51\u001b[0m   \u001b[39mdel\u001b[39;00m as_ref  \u001b[39m# Unused.\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m   \u001b[39mreturn\u001b[39;00m constant_op\u001b[39m.\u001b[39;49mconstant(value, dtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:263\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    168\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \n\u001b[0;32m    170\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 263\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    264\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:275\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    274\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 275\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    277\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[0;32m    278\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:300\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    299\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Implementation of eager constant.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[0;32m    301\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ML2_B\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m     97\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "model.fit(\n",
    "    x={'features_1d': X_train_1d, 'chromagram_input': X_train_chroma, 'mel_spectogram_input': X_train_mel, 'fourier_tempogram': X_train_fourier},\n",
    "    y=y_train.to_numpy(),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
