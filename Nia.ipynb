{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalation process\n",
    "  \n",
    "```\n",
    "    conda update --force conda\n",
    "    conda install -c conda-forge librosa\n",
    "    conda install -c \"conda-forge/label/cf201901\" librosa\n",
    "    conda install -c \"conda-forge/label/cf202003\" librosa\n",
    "    conda install -c \"conda-forge/label/gcc7\" librosa\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\L_IACD\\SoundClassification\\ML2-Project\\Nia.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/L_IACD/SoundClassification/ML2-Project/Nia.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/L_IACD/SoundClassification/ML2-Project/Nia.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/L_IACD/SoundClassification/ML2-Project/Nia.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlibrosa\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/L_IACD/SoundClassification/ML2-Project/Nia.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlibrosa\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/L_IACD/SoundClassification/ML2-Project/Nia.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models, layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\L_IACD\\SoundClassification\\UrbanSound8K\\audio')\n",
    "df = pd.read_csv('UrbanSound8K.csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the librosa package to load and display an audio file like this:\n",
    "\n",
    "sample_num=3 #pick a file to display\n",
    "#get the filename \n",
    "filename=df.recording_id[sample_num]+str('.flac')\n",
    "#define the beginning time of the signal\n",
    "tstart = df.t_min[sample_num] \n",
    "tend = df.t_max[sample_num] #define the end time of the signal\n",
    "y,sr=librosa.load('train/'+str(filename)) #load the file\n",
    "librosa.display.waveplot(y,sr=sr, x_axis='time', color='cyan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So you have to make your audio features look like an image.\n",
    "# Choose either 1D for a grayscale image (one feature) or 3D for a color image (to represent multiple features).\n",
    "# Scale and pad the audio features so that every “channel” is the same size.\n",
    "\n",
    "\n",
    "#This code was adapted from Nicolas Gervais on https://stackoverflow.com/questions/59241216/padding-numpy-arrays-to-a-specific-size on 1/10/2021\n",
    "def padding(array, xx, yy):\n",
    "    \"\"\"\n",
    "    :param array: numpy array\n",
    "    :param xx: desired height\n",
    "    :param yy: desirex width\n",
    "    :return: padded array\n",
    "    \"\"\"\n",
    "    h = array.shape[0]\n",
    "    w = array.shape[1]\n",
    "    a = max((xx - h) // 2,0)\n",
    "    aa = max(0,xx - a - h)\n",
    "    b = max(0,(yy - w) // 2)\n",
    "    bb = max(yy - b - w,0)\n",
    "    return np.pad(array, pad_width=((a, aa), (b, bb)), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The eventual shape of the features\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(y_cut):\n",
    "    max_size=1000 #my max audio file feature width\n",
    "\n",
    "    stft = padding(np.abs(librosa.stft(y_cut, n_fft=255, hop_length = 512)), 128, max_size)\n",
    "    MFCCs = padding(librosa.feature.mfcc(y_cut, n_fft=n_fft, hop_length=hop_length,n_mfcc=128),128,max_size)\n",
    "    spec_centroid = librosa.feature.spectral_centroid(y=y_cut, sr=sr)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y_cut, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y_cut, sr=sr)\n",
    "\n",
    "    #Now the padding part\n",
    "    image = np.array([padding(normalize(spec_bw),1, max_size)]).reshape(1,max_size)\n",
    "    image = np.append(image,padding(normalize(spec_centroid),1, max_size), axis=0) \n",
    "\n",
    "    #repeat the padded spec_bw,spec_centroid and chroma stft until they are stft and MFCC-sized\n",
    "    for i in range(0,9):\n",
    "        image = np.append(image,padding(normalize(spec_bw),1, max_size), axis=0)\n",
    "        image = np.append(image, padding(normalize(spec_centroid),1, max_size), axis=0)\n",
    "        image = np.append(image, padding(normalize(chroma_stft),12, max_size), axis=0)\n",
    "\n",
    "    image=np.dstack((image,np.abs(stft)))\n",
    "    image=np.dstack((image,MFCCs))\n",
    "\n",
    "    return image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
